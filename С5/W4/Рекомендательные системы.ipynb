{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание задачи\n",
    "Небольшой интернет-магазин попросил вас добавить ранжирование товаров в блок \"Смотрели ранее\" - в нем теперь надо показывать не последние просмотренные пользователем товары, а те товары из просмотренных, которые он наиболее вероятно купит. Качество вашего решения будет оцениваться по количеству покупок в сравнении с прошлым решением в ходе А/В теста, т.к. по доходу от продаж статзначимость будет достигаться дольше из-за разброса цен. Таким образом, ничего заранее не зная про корреляцию оффлайновых и онлайновых метрик качества, в начале проекта вы можете лишь постараться оптимизировать recall@k и precision@k.  \n",
    "\n",
    "Это задание посвящено построению простых бейзлайнов для этой задачи: ранжирование просмотренных товаров по частоте просмотров и по частоте покупок. Эти бейзлайны, с одной стороны, могут помочь вам грубо оценить возможный эффект от ранжирования товаров в блоке - например, чтобы вписать какие-то числа в коммерческое предложение заказчику, а с другой стороны, могут оказаться самым хорошим вариантом, если данных очень мало (недостаточно для обучения даже простых моделей)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Входные данные\n",
    "\n",
    "Вам дается две выборки с пользовательскими сессиями - id-шниками просмотренных и id-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n",
    "\n",
    "В файлах записаны сессии по одной в каждой строке. Формат сессии: id просмотренных товаров через , затем идёт ; после чего следуют id купленных товаров (если такие имеются), разделённые запятой. Например, **1,2,3,4;** или **1,2,3,4;5,6**.\n",
    "\n",
    "Гарантируется, что среди id купленных товаров все различные.\n",
    "\n",
    "**Важно:**\n",
    "\n",
    "- Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n",
    "- Если товар не встречался в обучающей выборке, его популярность равна 0.\n",
    "- Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    "- Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и k в recall@k / precision@k.\n",
    "\n",
    "**Задание**\n",
    "\n",
    "На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать)\n",
    "\n",
    "Реализуйте два алгоритма рекомендаций:\n",
    "- сортировка просмотренных id по популярности (частота появления в просмотренных),\n",
    "- сортировка просмотренных id по покупаемости (частота появления в покупках).\n",
    "\n",
    "Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие? Обратите внимание на различие качества на обучающей и тестовой выборке в случае рекомендаций по частотам покупки.\n",
    "\n",
    "Если частота одинаковая, то сортировать нужно по возрастанию момента просмотра (чем раньше появился в просмотренных, тем больше приоритет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"coursera_sessions_train.txt\", delimiter=\";\", names=[\"viewed\", \"purchased\"])\n",
    "data.viewed = data.viewed.str.split(',')\n",
    "data.purchased = data.purchased.str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"coursera_sessions_test.txt\", delimiter=\";\", names=[\"viewed\", \"purchased\"])\n",
    "data_test.viewed = data_test.viewed.str.split(',')\n",
    "data_test.purchased = data_test.purchased.str.split(',')\n",
    "data_test.dropna(inplace=True)\n",
    "data_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('73', 677), ('158', 641), ('204', 396), ('262', 387), ('162', 318)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewed_counter = Counter()\n",
    "\n",
    "for session in data.viewed:\n",
    "    for viewed_id in session:\n",
    "        viewed_counter[viewed_id] += 1\n",
    "\n",
    "viewed_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('158', 14), ('204', 12), ('3324', 11), ('73', 11), ('5569', 10)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchased_counter = Counter()\n",
    "\n",
    "for session in data.purchased:\n",
    "    for purchased_id in session:\n",
    "        purchased_counter[purchased_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_recall_precision(data, k, counter):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for i, session in data.iterrows():\n",
    "        session_recomendations = pd.unique(session.viewed).tolist()\n",
    "        session_recomendations.sort(key=lambda x: -counter[x])\n",
    "        session_recomendations = session_recomendations[:min(k, len(session_recomendations))]        \n",
    "        \n",
    "        used_recomendations = [x for x in session.purchased if x in session_recomendations]\n",
    "        precisions.append(len(used_recomendations)/k)\n",
    "        recalls.append(len(used_recomendations)/len(session.purchased))\n",
    "    return  np.mean(recalls), np.mean(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data, counter, file_name = None):\n",
    "    k1 = avg_recall_precision(data, 1, counter)\n",
    "    k5 = avg_recall_precision(data, 5, counter)\n",
    "    results = [round(i,2) for sub in [k1, k5] for i in sub]\n",
    "    if file_name is not None:\n",
    "        result = \" \".join([str(x) for x in result])\n",
    "        with open(file_name, \"w+\") as file:\n",
    "            file.write(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.44, 0.51, 0.82, 0.21]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = run_experiment(data, viewed_counter)\n",
    "print('Test set. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.69, 0.8, 0.93, 0.25]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment(data, purchased_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42, 0.48, 0.8, 0.2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment(data_test, viewed_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46, 0.53, 0.82, 0.21]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment(data_test, purchased_counter)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
